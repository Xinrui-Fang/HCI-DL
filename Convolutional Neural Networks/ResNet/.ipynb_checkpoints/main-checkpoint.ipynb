{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"AlexNet.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1HNEQV8P7MQfZ4P9Dg7eXxfjRHNGnTO5E\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "from ResNet import ResNet18\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "modelPath = './model.pkl'\n",
    "\n",
    "# 定义Summary_Writer\n",
    "writer = SummaryWriter('./Result')   # 数据存放在这个文件夹\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train() # 必备，将模型设置为训练模式\n",
    "    criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): # 从数据加载器迭代一个batch的数据\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # 清除所有优化的梯度\n",
    "        output = model(data) # 喂入数据并前向传播获取输出\n",
    "        loss = criterion(output, target).to(device) # 调用损失函数计算损失\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() #更新参数\n",
    "\n",
    "        if batch_idx % args.log_interval == 0: # 根据设置的显示间隔输出训练日志\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    writer.add_scalar('train_loss', loss.item(), epoch)\n",
    "\n",
    "def test(args, model, device, test_loader, epoch):\n",
    "    model.eval() # 必备，将模型设置为评估模式\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "    with torch.no_grad(): # 禁用梯度计算\n",
    "        for data, target in test_loader: # 从数据加载器迭代一个batch的数据\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).to(device).item() # # sum up batch loss\n",
    "            _, predicted = torch.max(output.data, 1)  # 返回每一行中最大值的那个元素，且返回其索引\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    writer.add_scalar('test_loss', test_loss, epoch)\n",
    "    writer.add_scalar('accuracy', correct / len(test_loader.dataset), epoch)\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='B',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=60, metavar='E',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    \n",
    "    args = parser.parse_known_args()[0]\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available() # 根据输入参数和实际cuda的有无决定是否使用GPU\n",
    "\n",
    "    torch.manual_seed(args.seed) # 设置随机种子，保证可重复性\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\") # 设置使用CPU or GPU\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {} # 设置数据加载的子进程数；是否返回之前将张量复制到cuda的页锁定内存\n",
    "    \n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./Cifar-10', train=True, download=True, transform=transforms.ToTensor())\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./Cifar-10', train=False, download=True, transform=transforms.ToTensor())\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    model = ResNet18().to(device) # 实例化网络模型\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum) # 实例化求解器\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1): # 循环调用train() and test() 进行epoch迭代\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader, epoch)\n",
    "\n",
    "        if epoch % 10 == 0: # save model every 10 epoches\n",
    "            torch.save(model, './model.pkl')\n",
    "\n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
